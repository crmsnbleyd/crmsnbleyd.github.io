---
Title: Self-attention
Summary: Explaining self attention, an important component of transformers.
Date: 2022-12-04 13:09
Status: published
Slug: attention
---
()[https://medium.com/nerd-for-tech/what-is-attention-in-nlp-f67411426e64]
